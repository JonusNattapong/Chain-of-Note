# Mistral AI Integration

This project provides a simple integration with the Mistral AI API, allowing you to utilize its capabilities for:

*   **Text Embeddings:** Generate vector representations of text.
*   **Optical Character Recognition (OCR):** Extract text from documents (e.g., PDFs).
*   **Agent Completions:** Interact with Mistral AI's language models for text generation and Q&A.

## Prerequisites

*   A Mistral AI API key. Obtain one from [Mistral AI](https://mistral.ai/).
*   Python 3.7+
*   The `mistralai` Python package: `pip install mistralai`

## API Key Setup

Before running the code, you **must** set the `MISTRAL_API_KEY` environment variable.  This is how the code authenticates with the Mistral AI API.

**Instructions:**

*   **Windows (Command Prompt):**
    ```
    set MISTRAL_API_KEY=your_api_key
    ```

*   **Windows (PowerShell):**
    ```powershell
    $env:MISTRAL_API_KEY = "your_api_key"
    ```

*   **macOS/Linux:**
    ```bash
    export MISTRAL_API_KEY=your_api_key
    ```

Replace `"your_api_key"` with your actual Mistral API key.

## Usage

The `mistral_integration.py` file contains three main functions:

1.  `get_embeddings(texts)`:
    *   Takes a list of strings (`texts`).
    *   Returns a list of embedding vectors from the Mistral AI API.
    *   Example:
        ```python
        texts = ["Hello", "World"]
        embeddings = get_embeddings(texts)
        print(embeddings)
        ```

2.  `process_ocr(document_url, include_image_base64=True)`:
    *   Takes a document URL (`document_url`) and an optional boolean to include base64 encoded images (`include_image_base64`).
    *   Returns the OCR result from the Mistral AI API.
    *   Example:
        ```python
        document_url = "https://example.com/document.pdf"
        ocr_result = process_ocr(document_url)
        print(ocr_result)
        ```

3.  `get_agent_completion(messages, max_tokens=100, model="mistral-large-latest")`:
    *    Takes a list of messages (`messages`), optional `max_tokens`, and the model name (`model`).
    *   Returns the completion generated by the Mistral AI agent.
    *   Example:
        ```python
        messages = [{"role": "user", "content": "What is the capital of France?"}]
        completion = get_agent_completion(messages)
        print(completion)
        ```

To run the examples, execute the script: `python mistral_integration.py`.  Make sure you've set the `MISTRAL_API_KEY` environment variable first.

## Workflow Diagram (Mindmap)

```mermaid
mindmap
  root((Mistral AI Integration))
    Embeddings
      User provides text input
      `get_embeddings` function
        Calls Mistral API (mistral-embed)
        Returns embedding vectors
    OCR
      User provides document URL
      `process_ocr` function
        Calls Mistral API (mistral-ocr-latest)
        Returns OCR results (text, optionally images)
    Agent Completions
      User provides messages (conversation history)
      `get_agent_completion` function
        Calls Mistral API (e.g., mistral-large-latest)
        Returns generated text completion
```

## Architecture Diagram

```mermaid
flowchart TB
    subgraph Client
        UI[User/Code]
    end

    subgraph Mistral_API_Integration
        API[mistral_integration.py]
    end
    
    subgraph External
        MAPI[Mistral AI API]
    end
    
    %% Client to API
    UI -->|Function Calls| API

    %% API to External
    API -->|API Requests| MAPI
    MAPI -->|API Responses| API
    
    classDef client fill:#f9d3a7,stroke:#333,stroke-width:1px
    classDef integration fill:#a7c7f9,stroke:#333,stroke-width:1px
    classDef external fill:#f9a7a7,stroke:#333,stroke-width:1px

    class Client client
    class Mistral_API_Integration integration
    class External external
```

## Data Flow Sequence

```mermaid
sequenceDiagram
    actor User
    participant Script as mistral_integration.py
    participant Mistral as Mistral AI API

    %% Embedding Flow
    User->>Script: Call get_embeddings(["text1", "text2"])
    Script->>Mistral: Request embeddings (mistral-embed)
    Mistral-->>Script: Return embeddings
    Script-->>User: Return embeddings

    %% OCR Flow
    User->>Script: Call process_ocr("document_url")
    Script->>Mistral: Request OCR (mistral-ocr-latest)
    Mistral-->>Script: Return OCR result
    Script-->>User: Return OCR result

    %% Agent Completion Flow
    User->>Script: Call get_agent_completion([{"role": "user", "content": "Question"}])
    Script->>Mistral: Request completion (e.g., mistral-large-latest)
    Mistral-->>Script: Return completion
    Script-->>User: Return completion
```

## Component Hierarchy
```mermaid
graph TD
    A[Mistral AI Integration] --> B[mistral_integration.py]
    B --> B1[get_embeddings]
    B --> B2[process_ocr]
    B --> B3[get_agent_completion]
    A --> C[Mistral AI API]

    style A fill:#f9f9f9,stroke:#333,stroke-width:2px
    style B fill:#cce8ff,stroke:#333,stroke-width:1px
    style C fill:#ffcccc,stroke:#333,stroke-width:1px
```

## Principles

*   **Modularity:** The code is organized into functions for each core API interaction (embeddings, OCR, agent completions). This makes it easy to use and extend.
*   **Error Handling:**  Basic error handling is included (checking for the API key and catching exceptions during API calls).  More robust error handling could be added.
*   **API Key Security:** The API key is *not* hardcoded. It's read from an environment variable, which is a more secure practice.
*   **Dependency Management:** The required `mistralai` package is specified, making it easy to install.
* **Clear separation of concerns:** Each function has a single, well-defined purpose.

## Further Improvements

*   **More robust error handling:** Implement more specific error handling and retry mechanisms.
*   **Asynchronous operations:** Use asynchronous requests (e.g., with `asyncio`) for improved performance, especially when processing multiple inputs.
*   **Configuration options:** Allow users to configure the model, maximum tokens, and other parameters more easily (e.g., through command-line arguments or a configuration file).
*   **Input validation:** Add validation for input parameters (e.g., checking the format of the document URL).
*   **Integration with other systems:**  This code could be integrated into a larger application, such as a document processing pipeline or a chatbot.

> Note: To properly view these diagrams, you need to render this markdown file in an environment that supports Mermaid diagrams (like GitHub, GitLab, or VS Code with the Markdown Preview Enhanced extension).

## Last Updated: 2025-03-18